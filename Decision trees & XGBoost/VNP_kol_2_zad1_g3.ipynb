{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Time-series Forecasting\n",
        "\n",
        "## Description\n",
        "The data consists of 52,416 observations of energy consumption on a 10-minute window. Every observation is described by the following feature columns.\n",
        "\n",
        "Your task is to **aggregate the observations on an interval of 2 hours**. For this time interval, using the values of the **4 previous time intervals**, forecast the target value one step in the future. Choose which features you are going to use.\n",
        "\n",
        "**You must train a Boosting model for the task. Choose the model based on the number, and type of features available.**\n",
        "\n",
        "\n",
        "\n",
        "Features:\n",
        "\n",
        "* Date: Time window of ten minutes.\n",
        "* Temperature: Weather Temperature.\n",
        "* Humidity: Weather Humidity.\n",
        "* WindSpeed: Wind Speed.\n",
        "* GeneralDiffuseFlows: “Diffuse flow” is a catchall term to describe low-temperature (< 0.2° to ~ 100°C) fluids that slowly discharge through sulfide mounds, fractured lava flows, and assemblages of bacterial mats and macrofauna.\n",
        "* DiffuseFlows\n",
        "\n",
        "Target:\n",
        "\n",
        "SolarPower\n",
        "\n",
        "## Dataset links:\n",
        "* [DS1](https://drive.google.com/file/d/1-Pcpb1xWpKc8Cgs-P7xqBFHw2NM0dBsA/view?usp=sharing)\n",
        "* [DS2](https://drive.google.com/file/d/1-Pul07w6LXpm-uo99qbNc86FHhwl4yQD/view?usp=sharing)"
      ],
      "metadata": {
        "id": "bPifLCgpTIOE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read the datasets"
      ],
      "metadata": {
        "id": "WRImf3uwjeVy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRn3umfJTDRx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merge the datasets (and pre-processing if needed)"
      ],
      "metadata": {
        "id": "ZNXTm_lwjhpb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mmX97V8ojhM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Group the datasets into time intervals of 2 hours"
      ],
      "metadata": {
        "id": "6cTsIz3vjjJr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bsufA_wIjloq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create lags"
      ],
      "metadata": {
        "id": "SDiLVboNjmbU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pia98cPkjtyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split the dataset into 80% training and 20% testing datasets"
      ],
      "metadata": {
        "id": "YiHdAHJJjuUL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kpdsa-tgjw-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the model, pre-process the data and make it suitable for training"
      ],
      "metadata": {
        "id": "eMx4eOy8j5vE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-MesyKu2j9Zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perofrm hyper-parameter optimization with a 5-fold cross validation.\n",
        "\n",
        "Important: Do not use many values for the hyper-parameters due to time constraints.\n",
        "\n",
        "KEEP IN MIND THE DATASET IS TIME-SERIES."
      ],
      "metadata": {
        "id": "VpO5gwPKkEZV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BwnSFVitkH_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fit the model with the best parameters on the training dataset"
      ],
      "metadata": {
        "id": "T251oIhoj_py"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VdHpwfROkCjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate the adequate metrics on the testing dataset"
      ],
      "metadata": {
        "id": "dnbQsioUkKys"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6L_L8NjckNV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize the targets against the predictions"
      ],
      "metadata": {
        "id": "UAuCQBvSkN1U"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kPkcMVoYkQRd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}